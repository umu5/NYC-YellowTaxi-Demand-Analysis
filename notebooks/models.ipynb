{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import expr\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, glm\n",
    "from pyspark.sql.functions import isnan, when, count, col, date_format, hour\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Tutorial 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.driver.memory', '4g')\n",
    "    .config('spark.executor.memory', '2g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet('../data/curated/*')\n",
    "zones = spark.read.csv('../data/taxi_zones/taxi+_zone_lookup.csv', \\\n",
    "                       header=True, inferSchema=True)\n",
    "wsdf = spark.read.parquet('../data/weather_curated/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns that we dont need to train the model on\n",
    "sdf = sdf.drop('VendorID', 'passenger_count', 'trip_distance', 'RatecodeID', \\\n",
    "                'store_and_fwd_flag', 'payment_type', 'fare_amount', 'extra', \\\n",
    "                'mta_tax', 'tip_amount', 'tolls_amount', \\\n",
    "                'improvement_surcharge', 'total_amount', \\\n",
    "                'congestion_surcharge', 'airport_fee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets start doing some modelling using weather data\n",
    "### we will fit linear model and see if these have an affect on weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_by_date_loc = (sdf.groupby(date_format('tpep_pickup_datetime', \\\n",
    "                                        'yyyy-MM-dd').alias('pickup_date'), \\\n",
    "                                        'PULocationID') \\\n",
    "                                    .count() \\\n",
    "                                    .withColumnRenamed('count', 'total_trips'))\n",
    "\n",
    "\n",
    "# Joining with weather data\n",
    "sdf2 = agg_by_date_loc.join(wsdf, agg_by_date_loc.pickup_date == wsdf.date, \\\n",
    "                            'inner').drop('pickup_date') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            total_trips   R-squared:                       0.034\n",
      "Model:                            OLS   Adj. R-squared:                  0.034\n",
      "Method:                 Least Squares   F-statistic:                     732.5\n",
      "Date:                Wed, 23 Aug 2023   Prob (F-statistic):               0.00\n",
      "Time:                        05:21:13   Log-Likelihood:            -8.7791e+05\n",
      "No. Observations:              105003   AIC:                         1.756e+06\n",
      "Df Residuals:                  104997   BIC:                         1.756e+06\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const            125.6259     12.840      9.784      0.000     100.459     150.793\n",
      "PULocationID       2.5243      0.042     60.376      0.000       2.442       2.606\n",
      "avg_wind_speed     2.3488      1.736      1.353      0.176      -1.053       5.751\n",
      "precipitation      0.3870      0.508      0.762      0.446      -0.608       1.382\n",
      "snowfall          -0.9271      0.294     -3.153      0.002      -1.503      -0.351\n",
      "avg_temp           0.8703      0.381      2.283      0.022       0.123       1.617\n",
      "==============================================================================\n",
      "Omnibus:                    53310.639   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           297990.940\n",
      "Skew:                           2.491   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.579   Cond. No.                         625.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "df = sdf2.toPandas()\n",
    "# Add a constant term to allow statsmodels to fit an intercept\n",
    "df['const'] = 1\n",
    "\n",
    "# Predictor variables (weather attributes + location)\n",
    "predictor_vars = ['const', 'PULocationID', 'avg_wind_speed', 'precipitation', \n",
    "                  'snowfall','avg_temp'\n",
    "]\n",
    "X = df[predictor_vars]\n",
    "\n",
    "\n",
    "# Response variable\n",
    "y = df['total_trips']\n",
    "\n",
    "model1 = sm.OLS(y, X).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            total_trips   R-squared:                       0.034\n",
      "Model:                            OLS   Adj. R-squared:                  0.034\n",
      "Method:                 Least Squares   F-statistic:                     1824.\n",
      "Date:                Wed, 23 Aug 2023   Prob (F-statistic):               0.00\n",
      "Time:                        05:35:41   Log-Likelihood:            -8.7792e+05\n",
      "No. Observations:              105003   AIC:                         1.756e+06\n",
      "Df Residuals:                  105000   BIC:                         1.756e+06\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const          140.5304      8.321     16.888      0.000     124.221     156.840\n",
      "PULocationID     2.5247      0.042     60.381      0.000       2.443       2.607\n",
      "is_weekday      10.7809      7.182      1.501      0.133      -3.296      24.858\n",
      "==============================================================================\n",
      "Omnibus:                    53311.856   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           297918.279\n",
      "Skew:                           2.491   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.578   Cond. No.                         481.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Extract the day of the week\n",
    "sdf_with_day = agg_by_date_loc.withColumn(\"day_of_week\",\\\n",
    "                              date_format(col(\"pickup_date\"), \"E\"))\n",
    "\n",
    "# Create a new column that represents 1 for weekday and 0 for weekend\n",
    "sdf_with_weekday = sdf_with_day.withColumn(\"is_weekday\", \\\n",
    "                                            when(col(\"day_of_week\") \\\n",
    "                                            .isin([\"Sat\", \"Sun\"]), 0) \\\n",
    "                                            .otherwise(1))\n",
    "sdf3 = sdf_with_weekday.drop('day_of_week')\n",
    "\n",
    "df = sdf3.toPandas()\n",
    "# Add a constant term to allow statsmodels to fit an intercept\n",
    "df['const'] = 1\n",
    "\n",
    "# Predictor variables (weather attributes + location)\n",
    "predictor_vars = ['const', 'PULocationID', 'is_weekday'\n",
    "]\n",
    "X = df[predictor_vars]\n",
    "\n",
    "\n",
    "# Response variable\n",
    "y = df['total_trips']\n",
    "\n",
    "model2 = sm.OLS(y, X).fit()\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 104:==================================================>    (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------+----------+\n",
      "|pickup_date|PULocationID|total_trips|is_weekday|\n",
      "+-----------+------------+-----------+----------+\n",
      "| 2022-08-02|         237|       5286|         1|\n",
      "+-----------+------------+-----------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf3.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+------------+------------+----------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|PULocationID|DOLocationID|is_weekday|\n",
      "+--------------------+---------------------+------------+------------+----------+\n",
      "| 2022-08-01 00:17:39|  2022-08-01 00:19:58|         114|         148|         1|\n",
      "| 2022-08-01 00:26:06|  2022-08-01 00:31:55|          79|         137|         1|\n",
      "| 2022-08-01 00:45:49|  2022-08-01 00:59:29|          79|          74|         1|\n",
      "| 2022-08-01 00:05:49|  2022-08-01 00:25:42|         138|         113|         1|\n",
      "| 2022-08-01 00:36:29|  2022-08-01 00:51:29|         137|          68|         1|\n",
      "| 2022-08-01 00:58:20|  2022-08-01 01:06:16|         132|         218|         1|\n",
      "| 2022-08-01 00:22:29|  2022-08-01 00:47:32|         138|         142|         1|\n",
      "| 2022-08-01 00:36:21|  2022-08-01 00:51:35|         138|         229|         1|\n",
      "| 2022-08-01 00:25:17|  2022-08-01 00:39:30|         209|         236|         1|\n",
      "| 2022-08-01 00:51:38|  2022-08-01 00:58:01|         224|          87|         1|\n",
      "| 2022-08-01 00:45:47|  2022-08-01 00:53:47|         186|         142|         1|\n",
      "| 2022-08-01 00:08:51|  2022-08-01 00:16:52|         161|         170|         1|\n",
      "| 2022-08-01 00:14:17|  2022-08-01 00:20:27|         246|          48|         1|\n",
      "| 2022-08-01 00:29:58|  2022-08-01 00:45:01|         246|          87|         1|\n",
      "| 2022-08-01 00:27:36|  2022-08-01 00:43:07|         138|           7|         1|\n",
      "| 2022-08-01 00:07:55|  2022-08-01 00:12:00|         229|         230|         1|\n",
      "| 2022-08-01 00:36:51|  2022-08-01 00:48:47|         132|         130|         1|\n",
      "| 2022-08-01 00:21:26|  2022-08-01 00:51:53|         132|          71|         1|\n",
      "| 2022-08-01 00:12:14|  2022-08-01 00:34:17|         138|          40|         1|\n",
      "| 2022-08-01 00:14:11|  2022-08-01 00:32:56|          48|         243|         1|\n",
      "+--------------------+---------------------+------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our analysis we saw that Manhattan has the most taxi demand but also JFK\n",
    "airport not being in Manhattan but still have significant demand so in our\n",
    "analysis of fitting logistic regression we will be using PU location belong to\n",
    "Manhattan and JFK airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " tpep_pickup_datetime  | 2022-08-01 00:17:39  \n",
      " tpep_dropoff_datetime | 2022-08-01 00:19:58  \n",
      " PULocationID          | 114                  \n",
      " DOLocationID          | 148                  \n",
      " Borough               | Manhattan            \n",
      " Zone                  | Greenwich Village... \n",
      " service_zone          | Yellow Zone          \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_zones = zones.filter(\n",
    "    (F.col(\"Borough\") == \"Manhattan\") | \n",
    "    (F.col(\"Zone\") == \"JFK Airport\")\n",
    ")\n",
    "\n",
    "# Perform the join\n",
    "result_sdf = sdf.join(\n",
    "    filtered_zones, \n",
    "    sdf.PULocationID == filtered_zones.LocationID, \n",
    "    \"inner\"\n",
    ").drop(filtered_zones.LocationID)\n",
    "\n",
    "result_sdf.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_sdf = result_sdf.sort(F.col(\"tpep_pickup_datetime\"))\n",
    "train_sdf = result_sdf.filter((F.col(\"tpep_pickup_datetime\") >= \"2022-02-01\") & \n",
    "                            (F.col(\"tpep_pickup_datetime\") <= \"2023-01-31\"))\n",
    "\n",
    "test_sdf = result_sdf.filter((F.col(\"tpep_pickup_datetime\") >= \"2023-02-01\") & \n",
    "                           (F.col(\"tpep_pickup_datetime\") <= \"2023-05-31\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+------------+------------+-------+-----------+------------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|PULocationID|DOLocationID|Borough|       Zone|service_zone|\n",
      "+--------------------+---------------------+------------+------------+-------+-----------+------------+\n",
      "| 2022-02-01 00:00:00|  2022-02-01 00:15:20|         132|         258| Queens|JFK Airport|    Airports|\n",
      "+--------------------+---------------------+------------+------------+-------+-----------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sdf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 236:===================================>                    (7 + 4) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35018152\n",
      "11370866\n",
      "75.48802175549395%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train = train_sdf.count()\n",
    "test = test_sdf.count()\n",
    "print(train)\n",
    "print(test)\n",
    "print(f\"{train/(test+train)*100}%\")\n",
    "train_hourly = train_sdf.withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))\n",
    "test_hourly = test_sdf.withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))\n",
    "drop_col = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'DOLocationID', \n",
    "            'Borough', 'Zone', 'service_zone'\n",
    "]\n",
    "train_hourly = train_hourly.drop(*drop_col)\n",
    "test_hourly = test_hourly.drop(*drop_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so we have 75% of the data for training and 25% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|PULocationID|pickup_hour|\n",
      "+------------+-----------+\n",
      "|         132|          0|\n",
      "+------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_hourly.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
