{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "import datetime\n",
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/22 00:57:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Tutorial 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.driver.memory', '4g')\n",
    "    .config('spark.executor.memory', '2g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATION: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- AWND: double (nullable = true)\n",
      " |-- PGTM: double (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- SNOW: double (nullable = true)\n",
      " |-- TAVG: double (nullable = true)\n",
      " |-- TMAX: double (nullable = true)\n",
      " |-- TMIN: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------\n",
      " STATION | USW00094789                      \n",
      " NAME    | JFK INTERNATIONAL AIRPORT, NY US \n",
      " DATE    | 2022-01-01                       \n",
      " AWND    | 2.8                              \n",
      " PGTM    | null                             \n",
      " PRCP    | 31.0                             \n",
      " SNOW    | 0.0                              \n",
      " TAVG    | 10.1                             \n",
      " TMAX    | 11.7                             \n",
      " TMIN    | 8.9                              \n",
      "only showing top 1 row\n",
      "\n",
      "[Row(STATION='USW00094789', NAME='JFK INTERNATIONAL AIRPORT, NY US', DATE='2023-05-31', AWND=2.3, PGTM=None, PRCP=0.0, SNOW=0.0, TAVG=14.7, TMAX=21.1, TMIN=8.9)]\n",
      "(516, 10)\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.read.parquet('../data/weather/weather_data.parquet')\n",
    "df = pd.read_parquet('../data/weather/weather_data.parquet')\n",
    "sdf.printSchema()\n",
    "sdf.show(1, vertical=True, truncate=100)\n",
    "# show last row\n",
    "print(sdf.tail(1))\n",
    "# check if there are any null values\n",
    "pd.isnull(df).sum()\n",
    "# count total records\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# after looking this there is no need for any preprocessing in weather data\n",
    "# in this case landing and raw data are same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets begin some preprocessing on yellow taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.read.parquet('../data/tlc/')\n",
    "sdf_jan = spark.read.parquet('../data/tlc/2022-01.parquet')\n",
    "sdf_jan.printSchema()\n",
    "sdf_feb_23 = spark.read.parquet('../data/tlc/2023-02.parquet')\n",
    "sdf_feb_23.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first before moving into raw layer data from 2022 have passenger count as double \n",
    "# lets cast all data to double and then save it to raw layer\n",
    "def cast_to_schema(year, start, end, temp_schema):\n",
    "    for month in range(start, end+1):\n",
    "        input_path = f'../data/tlc/{year}-{str(month).zfill(2)}.parquet'\n",
    "        output_path = f'../data/raw/{year}-{str(month).zfill(2)}.parquet'\n",
    "        sdf_malformed = spark.read.parquet(input_path)\n",
    "        sdf_malformed = sdf_malformed \\\n",
    "            .select([F.col(c).cast(temp_schema[i].dataType) for i, c in enumerate(sdf_malformed.columns)])\n",
    "        sdf_malformed \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# see if there is any non-whole number passenger_count. So it can be removed\n",
    "# before any proper data conversion can be made. Lets cast whole data to \n",
    "# jan 2022 schema which contains passenger_count as double\n",
    "tem_schema = sdf_jan.schema\n",
    "tem_schema\n",
    "cast_to_schema(\"2022\", 1, 12, tem_schema)\n",
    "cast_to_schema(\"2023\", 1, 5, tem_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:================================================>       (13 + 2) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with non-whole number passenger counts: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# see if there is any non-whole number passenger_count\n",
    "sdf = spark.read.parquet('../data/raw/*')\n",
    "non_whole_count = sdf.filter(col(\"passenger_count\") % 1 != 0).count()\n",
    "print(f\"Number of rows with non-whole number passenger counts: {non_whole_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# well we are now sure there wasn't any non-whole number passenger_count\n",
    "# so lets try to cast all datatype to 2023 february schema (proper schema)\n",
    "sdf_feb_23.printSchema()\n",
    "\n",
    "# also ensuring we have consistent casing\n",
    "consistent_col_casing = [F.col(col_name).alias(col_name.lower()) for col_name in sdf_feb_23.columns]\n",
    "sdf_feb_23 = sdf_feb_23.select(*consistent_col_casing)\n",
    "sdf_schema = sdf_feb_23.schema\n",
    "sdf_schema\n",
    "\n",
    "cast_to_schema(2022, 1, 12, sdf_schema)\n",
    "cast_to_schema(2023, 1, 5, sdf_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n",
      "-RECORD 0------------------------------------\n",
      " VendorID              | 1                   \n",
      " tpep_pickup_datetime  | 2022-10-01 00:03:41 \n",
      " tpep_dropoff_datetime | 2022-10-01 00:18:39 \n",
      " passenger_count       | 1                   \n",
      " trip_distance         | 1.7                 \n",
      " RatecodeID            | 1                   \n",
      " store_and_fwd_flag    | N                   \n",
      " PULocationID          | 249                 \n",
      " DOLocationID          | 107                 \n",
      " payment_type          | 1                   \n",
      " fare_amount           | 9.5                 \n",
      " extra                 | 3.0                 \n",
      " mta_tax               | 0.5                 \n",
      " tip_amount            | 2.65                \n",
      " tolls_amount          | 0.0                 \n",
      " improvement_surcharge | 0.3                 \n",
      " total_amount          | 15.95               \n",
      " congestion_surcharge  | 2.5                 \n",
      " airport_fee           | 0.0                 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.read.parquet('../data/raw/*')\n",
    "sdf.printSchema()\n",
    "sdf.show(1, vertical=True, truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done with raw data &#128512;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: boolean (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n",
      "-RECORD 0------------------------------------\n",
      " VendorID              | 1                   \n",
      " tpep_pickup_datetime  | 2022-10-01 00:03:41 \n",
      " tpep_dropoff_datetime | 2022-10-01 00:18:39 \n",
      " passenger_count       | 1                   \n",
      " trip_distance         | 1.7                 \n",
      " RatecodeID            | 1                   \n",
      " store_and_fwd_flag    | false               \n",
      " PULocationID          | 249                 \n",
      " DOLocationID          | 107                 \n",
      " payment_type          | 1                   \n",
      " fare_amount           | 9.5                 \n",
      " extra                 | 3.0                 \n",
      " mta_tax               | 0.5                 \n",
      " tip_amount            | 2.65                \n",
      " tolls_amount          | 0.0                 \n",
      " improvement_surcharge | 0.3                 \n",
      " total_amount          | 15.95               \n",
      " congestion_surcharge  | 2.5                 \n",
      " airport_fee           | 0.0                 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# according to data dictionary store_and_fwd_flag represents boolean condition\n",
    "# but currently have N and Y to represent No and Yes respectively\n",
    "sdf = sdf.withColumn('store_and_fwd_flag', \n",
    "    (F.col('store_and_fwd_flag') == 'Y').cast('boolean'))\n",
    "sdf.printSchema()\n",
    "sdf.show(1, vertical=True, truncate = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows:  55842484 Total columns:  19\n"
     ]
    }
   ],
   "source": [
    "# lets see the datashape before doing any further preprocessing\n",
    "tot_rows = sdf.count()\n",
    "tot_cols = len(sdf.columns)\n",
    "print(\"Total rows: \", tot_rows, \"Total columns: \", tot_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:================================================>       (13 + 2) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       0|                   0|                    0|        1796968|            0|   1796968|           1796968|           0|           0|           0|          0|    0|      0|         0|           0|                    0|           0|             1796968|    1796968|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# lets see which columns have missing values\n",
    "missing_values = sdf.agg(*[F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in sdf.columns])\n",
    "missing_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of missing passenger_count data: 3.217922755728416%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:================================================>       (13 + 2) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       0|                   0|                    0|              0|            0|         0|                 0|           0|           0|           0|          0|    0|      0|         0|           0|                    0|           0|                   0|          0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# well there is immense amount of missing passenger data. (imputation doesn't makes sense here)\n",
    "# so let drop those (1796968) rows\n",
    "missing_passenger = (missing_values.collect()[0]['passenger_count'] \n",
    "                    / tot_rows * 100)\n",
    "print(f'percentage of missing passenger_count data: {missing_passenger}%')\n",
    "sdf_clean = sdf.filter(col(\"passenger_count\").isNotNull())\n",
    "missing_values2 = sdf_clean.agg(*[F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in sdf_clean.columns])\n",
    "missing_values2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`after removing misssing passenger_count no other values seems to be missing` \\\n",
    "`How nice is this dataset? No missing values at all.` \\\n",
    "## lets do some outlier detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with time_difference greater than 5 hours: 62764, percentage: 0.1161317434734086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid drop off time: 23308,percentage:  0.043176753937998566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:===============================================>       (13 + 2) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining rows 53959444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 1. Add a new temporary column to record trip distance so can remove those\n",
    "# trips whcih span more than 5 hours\n",
    "sdf_with_difference = sdf_clean.withColumn(\"time_difference\", \n",
    "                                          col(\"tpep_dropoff_datetime\")\n",
    "                                          - col(\"tpep_pickup_datetime\"))\n",
    "\n",
    "# Count rows where the time_difference is more than 5 hours and remove them\n",
    "count_greater_than_5_hours = sdf_with_difference \\\n",
    "                             .filter(expr(\"time_difference \"\n",
    "                             \"> interval 5 hours\")).count()\n",
    "\n",
    "print(f\"Number of rows with time_difference greater than 5 hours: \"\n",
    "      f\"{count_greater_than_5_hours}, percentage: \" \n",
    "      f\"{count_greater_than_5_hours/sdf_with_difference.count() * 100}\")\n",
    "                                         \n",
    "sdf_clean2 = sdf_with_difference \\\n",
    "            .filter(expr(\"time_difference <= interval 5 hours\"))\n",
    "sdf_clean2 = sdf_clean2.drop(\"time_difference\")\n",
    "\n",
    "# also remove those rows that includes drop off time before pick up time a\n",
    "invalid_dropoff = sdf_clean2.filter(expr(\"tpep_dropoff_datetime \"\n",
    "                                    \"<= tpep_pickup_datetime\")).count()\n",
    "\n",
    "print(f\"Number of rows with invalid drop off time: {invalid_dropoff},\" \n",
    "      f\"percentage:  {invalid_dropoff/sdf_clean2.count() * 100}\")\n",
    "\n",
    "sdf_clean2 = sdf_clean2.filter(expr(\"tpep_dropoff_datetime \"\n",
    "                                    \"> tpep_pickup_datetime\"))\n",
    "print(f'remaining rows {sdf_clean2.count()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid location IDs: 943953 percentage: 1.749374956495104%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 117:===============================================>       (13 + 2) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53015491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# reomove Trips with a pick-up/drop-off location ID out of the range 1-263\n",
    "sdf_clean3 = sdf_clean2.filter(expr(\"PULocationID >= 1 \"\n",
    "                                    \"AND PULocationID <= 263 \"\n",
    "                                    \"AND DOLocationID >= 1 \"\n",
    "                                    \"AND DOLocationID <= 263\"))\n",
    "\n",
    "invalid_id = sdf_clean2.count() - sdf_clean3.count()\n",
    "print(f\"Number of invalid location IDs: {invalid_id}\",\n",
    "      f\"percentage: {invalid_id/sdf_clean2.count()*100}%\")\n",
    "print(sdf_clean3.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
